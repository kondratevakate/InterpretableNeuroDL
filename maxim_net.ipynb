{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbVC-fIYcwoA"
   },
   "outputs": [],
   "source": [
    "#!pip install torchio\n",
    "#!pip install nilearn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "# import torchio\n",
    "import os\n",
    "import nilearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBWPkt7SuenE"
   },
   "outputs": [],
   "source": [
    "#getting labels\n",
    "\n",
    "targets = pd.read_csv('D:/Target_and_data/Target.csv')\n",
    "y = pd.get_dummies(targets, columns=['Gender'])['Gender_M'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 58, 70, 58)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.load('D:/Target_and_data/X.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 1, 58, 70, 58)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjalzY4ZylGC"
   },
   "outputs": [],
   "source": [
    "class MriData(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MriData, self).__init__()\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbrgLdjw3uKQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) #may be that's bad idea to split using train_test_split. Instead of it - use indexes of data\n",
    "#del X, y #deleting for freeing space on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqWiIG3Wygpa"
   },
   "outputs": [],
   "source": [
    "train_dataset = MriData(X_train, y_train)\n",
    "test_dataset = MriData(X_test, y_test)\n",
    "#del X_train, X_test, y_train, y_test. #deleting for freeing space on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BttsN8kG3YyG"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=28, shuffle=True) \n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=28, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstAE(nn.Module):\n",
    "    def __init__(self, net):\n",
    "        super(MyFirstAE, self).__init__()\n",
    "        self.net = net\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Take a mini-batch as an input, encode it to the latent space and decode back to the original space\n",
    "        x_out = decoder(encoder(x))\n",
    "        :param x: torch.tensor, (MB, x_dim)\n",
    "        :return: torch.tensor, (MB, x_dim)\n",
    "        \"\"\"\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_size_conv(im_size,conv_kernel, conv_stride, padding):\n",
    "    return (im_size-conv_kernel+2*padding)/conv_stride +1\n",
    "def image_size_maxpool(im_size, pool_kernel,pool_stride):\n",
    "    return (im_size-pool_kernel)/pool_stride +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YTbF3NuselOt"
   },
   "outputs": [],
   "source": [
    "im_size = np.array([SCALE[0],SCALE[1],SCALE[2]])\n",
    "\n",
    "conv_kernel_1 = 3\n",
    "pool_kernel_1 = 2\n",
    "channels_1 = 5\n",
    "conv_stride_1 = 1\n",
    "pool_stride_1 = 2\n",
    "padding_1=0\n",
    "im_size = image_size_conv(im_size,conv_kernel_1, conv_stride_1, padding_1)\n",
    "im_size = image_size_maxpool(im_size, pool_kernel_1,pool_stride_1)\n",
    "\n",
    "conv_kernel_2 = 3\n",
    "pool_kernel_2 = 2\n",
    "channels_2 = 8\n",
    "conv_stride_2 = 1\n",
    "pool_stride_2 = 2\n",
    "padding_2 = 0\n",
    "im_size = image_size_conv(im_size,conv_kernel_2, conv_stride_2, padding_2)\n",
    "im_size = image_size_maxpool(im_size, pool_kernel_2,pool_stride_2)\n",
    "\n",
    "conv_kernel_3 = 3\n",
    "pool_kernel_3 = 2\n",
    "channels_3 = 16\n",
    "conv_stride_3 = 1\n",
    "pool_stride_3 = 2\n",
    "padding_3 = 0\n",
    "im_size = image_size_conv(im_size,conv_kernel_3, conv_stride_3, padding_3)\n",
    "im_size = image_size_maxpool(im_size, pool_kernel_3,pool_stride_3)\n",
    "im_size = im_size.astype('int')\n",
    "\n",
    "model =  nn.Sequential(\n",
    "    nn.Conv3d(in_channels=1,out_channels=channels_1,kernel_size=conv_kernel_1),\n",
    "    nn.BatchNorm3d(channels_1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(kernel_size=pool_kernel_1),\n",
    "    \n",
    "    nn.Conv3d(in_channels=channels_1,out_channels=channels_2,kernel_size=conv_kernel_2),\n",
    "    nn.BatchNorm3d(channels_2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(kernel_size=pool_kernel_2),\n",
    "    \n",
    "    \n",
    "    nn.Conv3d(in_channels=channels_2,out_channels=channels_3,kernel_size=conv_kernel_3),\n",
    "    nn.BatchNorm3d(channels_3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool3d(kernel_size=pool_kernel_3),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(np.prod(im_size)*channels_3,500),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.Linear(500,100),\n",
    "    torch.nn.ReLU(),\n",
    "    nn.Linear(100,2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,device, net, criterion, optimizer, train_loader, val_loader,scheduler=None, verbose=True, save_dir=None):\n",
    "    net.to(device)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        for X, y in train_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "#             print(y.shape)\n",
    "            out = net(X)\n",
    "#             print(out.shape)\n",
    "            loss = criterion(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # >>> your solution here <<<\n",
    "        \n",
    "\n",
    "        net.eval()\n",
    "        for X, y in val_loader:\n",
    "            # Compute the validation loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            out = net(X)\n",
    "            val_loss = criterion(out,y)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        freq = max(epochs//20,1)\n",
    "        if verbose and epoch%freq==0:\n",
    "            print('Epoch {}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = MyFirstAE(model) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=(15,25 ), gamma=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 || Loss:  Train 0.3448 | Validation 0.3694\n",
      "Epoch 4/50 || Loss:  Train 0.5481 | Validation 0.1538\n",
      "Epoch 6/50 || Loss:  Train 0.3455 | Validation 0.0954\n",
      "Epoch 8/50 || Loss:  Train 0.0972 | Validation 0.0684\n",
      "Epoch 10/50 || Loss:  Train 0.2895 | Validation 0.0713\n",
      "Epoch 12/50 || Loss:  Train 0.3372 | Validation 0.0466\n",
      "Epoch 14/50 || Loss:  Train 0.0718 | Validation 0.0348\n",
      "Epoch 16/50 || Loss:  Train 0.0256 | Validation 0.0645\n",
      "Epoch 18/50 || Loss:  Train 0.0077 | Validation 0.1506\n",
      "Epoch 20/50 || Loss:  Train 0.0052 | Validation 0.0571\n",
      "Epoch 22/50 || Loss:  Train 0.0020 | Validation 0.0424\n",
      "Epoch 24/50 || Loss:  Train 0.0018 | Validation 0.0882\n",
      "Epoch 26/50 || Loss:  Train 0.0003 | Validation 0.0396\n",
      "Epoch 28/50 || Loss:  Train 0.0004 | Validation 0.0398\n",
      "Epoch 30/50 || Loss:  Train 0.0007 | Validation 0.0484\n",
      "Epoch 32/50 || Loss:  Train 0.0003 | Validation 0.0219\n",
      "Epoch 34/50 || Loss:  Train 0.0001 | Validation 0.0301\n",
      "Epoch 36/50 || Loss:  Train 0.0000 | Validation 0.0161\n",
      "Epoch 38/50 || Loss:  Train 0.0000 | Validation 0.0106\n",
      "Epoch 40/50 || Loss:  Train 0.0000 | Validation 0.0120\n",
      "Epoch 42/50 || Loss:  Train 0.0000 | Validation 0.0095\n",
      "Epoch 44/50 || Loss:  Train 0.0000 | Validation 0.0080\n",
      "Epoch 46/50 || Loss:  Train 0.0000 | Validation 0.0091\n",
      "Epoch 48/50 || Loss:  Train 0.0000 | Validation 0.0082\n",
      "Epoch 50/50 || Loss:  Train 0.0000 | Validation 0.0082\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train(epochs,device, net, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "mri_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
