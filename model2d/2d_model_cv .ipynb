{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import json, os\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data along the axis with shape 70\n",
    "# into 23 slices of width 3, ignore the last layer\n",
    "\n",
    "class MriData2d_3(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MriData2d, self).__init__()\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0] * 23\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = idx // 23\n",
    "        j = idx % 23\n",
    "        return self.X[i,:,3*j:3*j+3,:].permute(1, 0, 2), self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data along the axis with shape 70\n",
    "# into 14 slices of width 5\n",
    "class MriData2d_5(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MriData2d, self).__init__()\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0] * 14\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = idx // 14\n",
    "        j = idx % 14\n",
    "        return self.X[i,:,5*j:5*j+5,:].permute(1, 0, 2), self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hidden(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(hidden, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "        nn.Conv2d(c_in, c_out, 3),\n",
    "        nn.BatchNorm2d(c_out),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hidden_res(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(hidden, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "        nn.Conv2d(c_in, c_out, 3),\n",
    "        nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "        self.act_block = nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.act_block(x + self.conv_block(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNet2d_3(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNet2d, self).__init__()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, c, 3, padding=1),\n",
    "            hidden(c, c), \n",
    "            hidden(c, 2*c), \n",
    "            hidden(2*c, 4*c)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(4*c*5*5, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNet2d_5(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNet2d, self).__init__()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Conv2d(5, c, 3, padding=1),\n",
    "            hidden(c, c), \n",
    "            hidden(c, 2*c), \n",
    "            hidden(2*c, 4*c)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(4*c*5*5, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNet2d_res3(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNet2d, self).__init__()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, c, 3, padding=1),\n",
    "            hidden_res(c, c), \n",
    "            hidden_res(c, 2*c), \n",
    "            hidden_res(2*c, 4*c)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(4*c*5*5, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNet2d_res5(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNet2d, self).__init__()\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Conv2d(5, c, 3, padding=1),\n",
    "            hidden_res(c, c), \n",
    "            hidden_res(c, 2*c), \n",
    "            hidden_res(2*c, 4*c)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear = nn.Linear(4*c*5*5, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(net, data_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = net(data)\n",
    "        pred = out.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        del data, target\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    return accuracy.item()\n",
    "\n",
    "def get_loss(net, data_loader):\n",
    "    net.eval()\n",
    "    loss = 0 \n",
    "    for data, target in data_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = net(data)\n",
    "        loss += criterion(out, target).item()*len(data)\n",
    "\n",
    "        del data, target\n",
    "\n",
    "    return loss / len(data_loader.dataset)\n",
    "\n",
    "\n",
    "def train(epochs, net, criterion, optimizer, train_loader, val_loader, scheduler=None, verbose=True):\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    train_loss_list.append(get_loss(net, train_loader))\n",
    "    val_loss_list.append(get_loss(net, val_loader))\n",
    "    train_acc_list.append(get_accuracy(net, train_loader))\n",
    "    val_acc_list.append(get_accuracy(net, val_loader))\n",
    "    if verbose:\n",
    "        print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(0, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
    "\n",
    "    net.to(device)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        for X, y in train_loader:\n",
    "            # Perform one step of minibatch stochastic gradient descent\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = net(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        # define NN evaluation, i.e. turn off dropouts, batchnorms, etc.\n",
    "        net.eval()\n",
    "        for X, y in val_loader:\n",
    "            # Compute the validation loss\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            out = net(X)\n",
    "         \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        \n",
    "        train_loss_list.append(get_loss(net, train_loader))\n",
    "        val_loss_list.append(get_loss(net, val_loader))\n",
    "        train_acc_list.append(get_accuracy(net, train_loader))\n",
    "        val_acc_list.append(get_accuracy(net, val_loader))\n",
    "        \n",
    "        train_loss_list = np.array(train_loss_list)\n",
    "        val_loss_list = np.array(val_loss_list)\n",
    "        train_acc_list = np.array(train_acc_list)\n",
    "        val_acc_list = np.array(val_acc_list)\n",
    "\n",
    "        freq = 1\n",
    "        if verbose and epoch%freq==0:\n",
    "            print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f} || Accuracy:  Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, train_loss_list[-1], val_loss_list[-1], train_acc_list[-1], val_acc_list[-1]))\n",
    "        \n",
    "    return train_loss_list, val_loss_list, train_acc_list, val_acc_list\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(name, d, c):\n",
    "    if name == 'conv':\n",
    "        if d == 3:\n",
    "            return MriNet2d_3(c)\n",
    "        elif d == 5:\n",
    "            return MriNet2d_5(c)\n",
    "        else:\n",
    "            print('Wrong d')\n",
    "    elif name == 'res':\n",
    "        if d == 3:\n",
    "            return MriNet2d_res3(c)\n",
    "        elif d == 5:\n",
    "            return MriNet2d_res5(c)\n",
    "        else:\n",
    "            print('Wrong d')\n",
    "    else:\n",
    "            print('Wrong name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_class(d):\n",
    "    if d == 3:\n",
    "        return MriData2d_3\n",
    "    elif d == 5:\n",
    "        return MriData2d_5\n",
    "    else:\n",
    "        print('Wrong d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_experiment(name, d, c=32):\n",
    "    X, y = np.load('../data/tensors.npy'), np.load('../data/labels.npy')\n",
    "    i = 0\n",
    "    results = {}\n",
    "    for j in range(5):\n",
    "        results[j] = {}\n",
    "        \n",
    "    for train_idx, test_idx StratifiedKFold().split(X, y):\n",
    "        model = init_model(name, d, c)\n",
    "        dataset_type = dataset_class(d)\n",
    "        train_dataset = dataset_type(X[train_idx], y[train_idx])\n",
    "        test_dataset = dataset_type(X[test_idx], y[test_idx])\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=3e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15, 25], gamma=0.5)\n",
    "        print(f'Fold {i} out of 5')\n",
    "        train_losses, val_losses, train_accs, val_accs =  train(35, model, criterion, optimizer, train_loader,\n",
    "                                                                val_loader, scheduler=None, verbose=False)\n",
    "        results[i]['train_loss'] = train_losses\n",
    "        results[i]['val_loss'] = val_losses\n",
    "        results[i]['train_acc'] = train_accs\n",
    "        results[i]['val_acc'] = val_accs\n",
    "        if d == 3:\n",
    "            features_dim = 23\n",
    "        elif d == 5:\n",
    "            features_dim = 14\n",
    "        else:\n",
    "            print('Wrong d')\n",
    "            \n",
    "        new_features = np.zeros((len(test_idx), features_dim))\n",
    "        for idx in range(517*features_dim):\n",
    "            i = idx // features_dim\n",
    "            j = idx % features_dim\n",
    "            x = X[test_idx][i,:,5*j:5*j+5,:].permute(1, 0, 2).unsqueeze(0)\n",
    "            y = model(x).squeeze()\n",
    "            ind = np.argmax(y.detach().numpy())\n",
    "            new_features[i, j] = ind\n",
    "        y_pred = np.mean(new_features, axis=1)\n",
    "        y_pred = np.where(y_pred>0.5, 1, 0)\n",
    "        acc = accuracy_score(y[test_idx] y_pred)\n",
    "        results[i]['test_acc_fin'] = acc\n",
    "        \n",
    "        new_features = np.zeros((len(train_idx), features_dim))\n",
    "        for idx in range(517*features_dim):\n",
    "            i = idx // features_dim\n",
    "            j = idx % features_dim\n",
    "            x = X[train_idx][i,:,5*j:5*j+5,:].permute(1, 0, 2).unsqueeze(0)\n",
    "            y = model(x).squeeze()\n",
    "            ind = np.argmax(y.detach().numpy())\n",
    "            new_features[i, j] = ind\n",
    "        y_pred = np.mean(new_features, axis=1)\n",
    "        y_pred = np.where(y_pred>0.5, 1, 0)\n",
    "        acc = accuracy_score(y[train_idx] y_pred)\n",
    "        results[i]['train_acc_fin'] = acc\n",
    "        i += 1\n",
    "        \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 32\n",
    "d = 3\n",
    "#d = 5\n",
    "model = 'conv'\n",
    "#model = 'res'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "results = cross_val_experiment(name, d, c)\n",
    "with open(f'{name}_{d}_2d_cv_results.json', 'w') as fp:\n",
    "    json.dump(fp, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
